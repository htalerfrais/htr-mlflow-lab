experiment_name: "Qwen2.5-VL OCR (local lines)"
run_name: "qwen2.5-vl-7b-IAM"

pipeline: "line_to_text"

dataset:
  name: "Teklia/IAM-line"

preprocessor:
  - "identity"

model:
  name: "qwen_vl"
  pretrained_model_name: "Qwen/Qwen2.5-VL-3B-Instruct"
  # For big models, "auto" typically works best (requires a working HF setup).
  device_map: "auto"
  torch_dtype: "auto"
  max_new_tokens: 256
  prompt: "Read and transcribe all text in the image exactly. Output only the transcription."

